{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as datasets, pandas, matplotlib, and IPython.display for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladpalamarchuk/Documents/Data-Project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries such as datasets, pandas, matplotlib, and IPython.display for visualization\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the IMDB Dataset\n",
    "Load the IMDB dataset using the datasets library and convert it to pandas DataFrames for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I love sci-fi and am willing to put up with a ...      0\n",
       "1  Worth the entertainment value of a rental, esp...      0\n",
       "2  its a totally average film with a few semi-alr...      0\n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
       "4  First off let me say, If you haven't enjoyed a...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is just a precious little diamond. The pl...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I say this is my favourite film of all ti...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I saw this movie because I am a huge fan of th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being that the only foreign films I usually li...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After seeing Point of No Return (a great movie...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This is just a precious little diamond. The pl...     -1\n",
       "1  When I say this is my favourite film of all ti...     -1\n",
       "2  I saw this movie because I am a huge fan of th...     -1\n",
       "3  Being that the only foreign films I usually li...     -1\n",
       "4  After seeing Point of No Return (a great movie...     -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the IMDB Dataset\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Convert the dataset to pandas DataFrames for easier manipulation\n",
    "imdb_train_df = pd.DataFrame(imdb_dataset['train'])\n",
    "imdb_test_df = pd.DataFrame(imdb_dataset['test'])\n",
    "imdb_unsupervised_df = pd.DataFrame(imdb_dataset['unsupervised'])\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "display(imdb_train_df.head())\n",
    "display(imdb_test_df.head())\n",
    "display(imdb_unsupervised_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset Structure\n",
    "Examine the dataset structure, including features, splits, and basic statistics using methods like info() and describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the structure of the training dataset\n",
    "print(\"Training Dataset Info:\")\n",
    "imdb_train_df.info()\n",
    "\n",
    "print(\"\\nTraining Dataset Description:\")\n",
    "display(imdb_train_df.describe())\n",
    "\n",
    "# Explore the structure of the test dataset\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "imdb_test_df.info()\n",
    "\n",
    "print(\"\\nTest Dataset Description:\")\n",
    "display(imdb_test_df.describe())\n",
    "\n",
    "# Explore the structure of the unsupervised dataset\n",
    "print(\"\\nUnsupervised Dataset Info:\")\n",
    "imdb_unsupervised_df.info()\n",
    "\n",
    "print(\"\\nUnsupervised Dataset Description:\")\n",
    "display(imdb_unsupervised_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Dataset Samples\n",
    "Show samples from the dataset using display() function to properly format text data in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dataset Samples\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "display(imdb_train_df.head())\n",
    "display(imdb_test_df.head())\n",
    "display(imdb_unsupervised_df.head())\n",
    "\n",
    "# Explore the structure of the training dataset\n",
    "print(\"Training Dataset Info:\")\n",
    "imdb_train_df.info()\n",
    "\n",
    "print(\"\\nTraining Dataset Description:\")\n",
    "display(imdb_train_df.describe())\n",
    "\n",
    "# Explore the structure of the test dataset\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "imdb_test_df.info()\n",
    "\n",
    "print(\"\\nTest Dataset Description:\")\n",
    "display(imdb_test_df.describe())\n",
    "\n",
    "# Explore the structure of the unsupervised dataset\n",
    "print(\"\\nUnsupervised Dataset Info:\")\n",
    "imdb_unsupervised_df.info()\n",
    "\n",
    "print(\"\\nUnsupervised Dataset Description:\")\n",
    "display(imdb_unsupervised_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Text Data\n",
    "Analyze text properties such as review length, word frequency, and distribution of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Text Data\n",
    "\n",
    "# Analyze review length\n",
    "imdb_train_df['review_length'] = imdb_train_df['text'].apply(len)\n",
    "imdb_test_df['review_length'] = imdb_test_df['text'].apply(len)\n",
    "imdb_unsupervised_df['review_length'] = imdb_unsupervised_df['text'].apply(len)\n",
    "\n",
    "# Plot review length distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(imdb_train_df['review_length'], bins=50, alpha=0.5, label='Train')\n",
    "plt.hist(imdb_test_df['review_length'], bins=50, alpha=0.5, label='Test')\n",
    "plt.hist(imdb_unsupervised_df['review_length'], bins=50, alpha=0.5, label='Unsupervised')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Review Length Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Analyze word frequency\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_word_freq(text_series):\n",
    "    words = ' '.join(text_series).lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', words)\n",
    "    return Counter(words)\n",
    "\n",
    "train_word_freq = get_word_freq(imdb_train_df['text'])\n",
    "test_word_freq = get_word_freq(imdb_test_df['text'])\n",
    "unsupervised_word_freq = get_word_freq(imdb_unsupervised_df['text'])\n",
    "\n",
    "# Display the most common words\n",
    "print(\"Most common words in training set:\")\n",
    "print(train_word_freq.most_common(10))\n",
    "\n",
    "print(\"\\nMost common words in test set:\")\n",
    "print(test_word_freq.most_common(10))\n",
    "\n",
    "print(\"\\nMost common words in unsupervised set:\")\n",
    "print(unsupervised_word_freq.most_common(10))\n",
    "\n",
    "# Distribution of labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "imdb_train_df['label'].value_counts().plot(kind='bar', alpha=0.5, label='Train')\n",
    "imdb_test_df['label'].value_counts().plot(kind='bar', alpha=0.5, label='Test')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Label Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset Statistics\n",
    "Create visualizations to better understand the dataset, including distribution of review lengths, word clouds, and label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Dataset Statistics\n",
    "\n",
    "# Import necessary libraries for visualization\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Plot distribution of review lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(imdb_train_df['review_length'], bins=50, kde=True, color='blue', label='Train')\n",
    "sns.histplot(imdb_test_df['review_length'], bins=50, kde=True, color='green', label='Test')\n",
    "sns.histplot(imdb_unsupervised_df['review_length'], bins=50, kde=True, color='red', label='Unsupervised')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Review Length Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Generate word clouds for each dataset\n",
    "train_text = ' '.join(imdb_train_df['text'])\n",
    "test_text = ' '.join(imdb_test_df['text'])\n",
    "unsupervised_text = ' '.join(imdb_unsupervised_df['text'])\n",
    "\n",
    "train_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(train_text)\n",
    "test_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(test_text)\n",
    "unsupervised_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(unsupervised_text)\n",
    "\n",
    "# Display the word clouds\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(train_wordcloud, interpolation='bilinear')\n",
    "plt.title('Train Set Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_wordcloud, interpolation='bilinear')\n",
    "plt.title('Test Set Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(unsupervised_wordcloud, interpolation='bilinear')\n",
    "plt.title('Unsupervised Set Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot label distribution for train and test datasets\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='label', data=imdb_train_df, alpha=0.5, label='Train')\n",
    "sns.countplot(x='label', data=imdb_test_df, alpha=0.5, label='Test')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Label Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9790315628051758}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Используем русскоязычную модель\n",
    "classifier = pipeline(\"text-classification\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "result = classifier(\"Я люблю этот фильм!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Используем существующие пути к папкам\n",
    "# labeled_dir = \"/Users/vladpalamarchuk/Documents/Data-Project/labeled_data\"\n",
    "# sentiment_dir = os.path.join(labeled_dir, \"sentiment_results\")\n",
    "# os.makedirs(sentiment_dir, exist_ok=True)  # Создаем подпапку для результатов анализа\n",
    "\n",
    "# # Используем русскоязычную модель\n",
    "# classifier = pipeline(\"text-classification\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "\n",
    "# # Определяем базовые имена файлов\n",
    "# base_name = \"imdb_text\"\n",
    "# # Находим существующие файлы, чтобы определить следующий номер\n",
    "# existing_files = [f for f in os.listdir(sentiment_dir) if f.startswith(base_name) and f.endswith('.csv')]\n",
    "# next_number = 1\n",
    "# if existing_files:\n",
    "#     # Извлекаем номера из существующих файлов\n",
    "#     numbers = [int(f.replace(base_name, '').replace('.csv', '')) for f in existing_files if f.replace(base_name, '').replace('.csv', '').isdigit()]\n",
    "#     if numbers:\n",
    "#         next_number = max(numbers) + 1\n",
    "\n",
    "# # Создаем файлы для сохранения результатов\n",
    "# results_file = os.path.join(sentiment_dir, f\"{base_name}{next_number}.csv\")\n",
    "# json_file = os.path.join(sentiment_dir, f\"{base_name}{next_number}.json\")\n",
    "\n",
    "# # Выбираем датасет для анализа (можно заменить на imdb_test_df или imdb_unsupervised_df)\n",
    "# dataset_to_analyze = imdb_train_df.head(100)  # Анализируем первые 100 записей для примера\n",
    "\n",
    "# print(f\"Начинаем анализ датасета, всего записей: {len(dataset_to_analyze)}\")\n",
    "\n",
    "# # Создаем список для хранения результатов\n",
    "# results_data = []\n",
    "\n",
    "# # Обрабатываем каждую запись в датасете\n",
    "# for index, row in dataset_to_analyze.iterrows():\n",
    "#     text = row['text']\n",
    "#     original_label = row['label']\n",
    "    \n",
    "#     # Ограничиваем длину текста для анализа (модель имеет ограничение)\n",
    "#     text_for_analysis = text[:512]\n",
    "    \n",
    "#     # Получаем результат анализа тональности\n",
    "#     sentiment_result = classifier(text_for_analysis)\n",
    "    \n",
    "#     # Извлекаем метку и уверенность\n",
    "#     sentiment_label = sentiment_result[0]['label']\n",
    "#     confidence = sentiment_result[0]['score']\n",
    "    \n",
    "#     # Добавляем результат в список\n",
    "#     results_data.append({\n",
    "#         'index': index,\n",
    "#         'original_text': text[:200] + '...' if len(text) > 200 else text,  # Сокращаем для вывода\n",
    "#         'original_label': original_label,\n",
    "#         'sentiment_label': sentiment_label,\n",
    "#         'confidence': confidence\n",
    "#     })\n",
    "    \n",
    "#     # Выводим прогресс каждые 10 записей\n",
    "#     if (index + 1) % 10 == 0:\n",
    "#         print(f\"Обработано {index + 1} записей\")\n",
    "\n",
    "# # Создаем DataFrame из результатов\n",
    "# results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# # Сохраняем результаты в CSV\n",
    "# results_df.to_csv(results_file, index=False)\n",
    "\n",
    "# # Сохраняем также в JSON для более удобного использования\n",
    "# with open(json_file, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(results_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# print(f\"\\nАнализ завершен!\")\n",
    "# print(f\"Обработано записей: {len(results_data)}\")\n",
    "# print(f\"Результаты сохранены в: {results_file}\")\n",
    "# print(f\"JSON-версия сохранена в: {json_file}\")\n",
    "\n",
    "# # Выводим первые 5 результатов для просмотра\n",
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Читаем файл: /Users/vladpalamarchuk/Documents/Data-Project/dataset/20-sentences.txt\n",
      "Начинаем анализ текста, всего предложений: 20\n",
      "Обработано 5 предложений\n",
      "Обработано 10 предложений\n",
      "Обработано 15 предложений\n",
      "Обработано 20 предложений\n",
      "\n",
      "Анализ завершен!\n",
      "Обработано предложений: 20\n",
      "Результаты сохранены в: /Users/vladpalamarchuk/Documents/Data-Project/labeled_data/sentiment_results/text_sentiment1.csv\n",
      "JSON-версия сохранена в: /Users/vladpalamarchuk/Documents/Data-Project/labeled_data/sentiment_results/text_sentiment1.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>original_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.\\tСолнце светит ярко и дарит тепло.</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.732100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.\\tСегодня я чувствую радость и вдохновение.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.751456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.\\tУлыбки прохожих наполняют меня счастьем.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.942914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.\\tМир вокруг кажется прекрасным и уютным.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.969522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.\\tКаждое утро приносит надежду на лучшее.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.980489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  original_text sentiment_label  \\\n",
       "0      0          1.\\tСолнце светит ярко и дарит тепло.         NEUTRAL   \n",
       "1      1  2.\\tСегодня я чувствую радость и вдохновение.        NEGATIVE   \n",
       "2      2   3.\\tУлыбки прохожих наполняют меня счастьем.        POSITIVE   \n",
       "3      3    4.\\tМир вокруг кажется прекрасным и уютным.        POSITIVE   \n",
       "4      4    5.\\tКаждое утро приносит надежду на лучшее.        POSITIVE   \n",
       "\n",
       "   confidence  \n",
       "0    0.732100  \n",
       "1    0.751456  \n",
       "2    0.942914  \n",
       "3    0.969522  \n",
       "4    0.980489  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Пути к папкам\n",
    "dataset_path = \"/Users/vladpalamarchuk/Documents/Data-Project/dataset\"\n",
    "labeled_dir = \"/Users/vladpalamarchuk/Documents/Data-Project/labeled_data\"\n",
    "sentiment_dir = os.path.join(labeled_dir, \"sentiment_results\")\n",
    "os.makedirs(sentiment_dir, exist_ok=True)  # Создаем подпапку для результатов анализа\n",
    "\n",
    "# Путь к файлу с текстом\n",
    "text_file = os.path.join(dataset_path, \"20-sentences.txt\")\n",
    "\n",
    "# Используем русскоязычную модель\n",
    "classifier = pipeline(\"text-classification\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "\n",
    "# Определяем базовые имена файлов\n",
    "base_name = \"text_sentiment\"\n",
    "# Находим существующие файлы, чтобы определить следующий номер\n",
    "existing_files = [f for f in os.listdir(sentiment_dir) if f.startswith(base_name) and f.endswith('.csv')]\n",
    "next_number = 1\n",
    "if existing_files:\n",
    "    # Извлекаем номера из существующих файлов\n",
    "    numbers = [int(f.replace(base_name, '').replace('.csv', '')) for f in existing_files if f.replace(base_name, '').replace('.csv', '').isdigit()]\n",
    "    if numbers:\n",
    "        next_number = max(numbers) + 1\n",
    "\n",
    "# Создаем файлы для сохранения результатов\n",
    "results_file = os.path.join(sentiment_dir, f\"{base_name}{next_number}.csv\")\n",
    "json_file = os.path.join(sentiment_dir, f\"{base_name}{next_number}.json\")\n",
    "\n",
    "# Читаем текстовый файл\n",
    "print(f\"Читаем файл: {text_file}\")\n",
    "with open(text_file, 'r', encoding='utf-8') as file:\n",
    "    lines = [line.strip() for line in file if line.strip()]  # Убираем пустые строки\n",
    "\n",
    "print(f\"Начинаем анализ текста, всего предложений: {len(lines)}\")\n",
    "\n",
    "# Создаем список для хранения результатов\n",
    "results_data = []\n",
    "\n",
    "# Обрабатываем каждое предложение\n",
    "for index, text in enumerate(lines):\n",
    "    # Ограничиваем длину текста для анализа (модель имеет ограничение)\n",
    "    text_for_analysis = text[:512]\n",
    "    \n",
    "    # Получаем результат анализа тональности\n",
    "    sentiment_result = classifier(text_for_analysis)\n",
    "    \n",
    "    # Извлекаем метку и уверенность\n",
    "    sentiment_label = sentiment_result[0]['label']\n",
    "    confidence = sentiment_result[0]['score']\n",
    "    \n",
    "    # Добавляем результат в список\n",
    "    results_data.append({\n",
    "        'index': index,\n",
    "        'original_text': text,\n",
    "        'sentiment_label': sentiment_label,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "    \n",
    "    # Выводим прогресс каждые 5 предложений\n",
    "    if (index + 1) % 5 == 0:\n",
    "        print(f\"Обработано {index + 1} предложений\")\n",
    "\n",
    "# Создаем DataFrame из результатов\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Сохраняем результаты в CSV\n",
    "results_df.to_csv(results_file, index=False)\n",
    "\n",
    "# Сохраняем также в JSON для более удобного использования\n",
    "with open(json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nАнализ завершен!\")\n",
    "print(f\"Обработано предложений: {len(results_data)}\")\n",
    "print(f\"Результаты сохранены в: {results_file}\")\n",
    "print(f\"JSON-версия сохранена в: {json_file}\")\n",
    "\n",
    "# Выводим первые 5 результатов для просмотра\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
